<!DOCTYPE html>
<html lang="en">
  <head>	
    <meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="author" content="druid">

<title>Druid | Understanding Druid Real-time Ingestion</title>
<link rel="alternate" type="application/atom+xml" href="http://druid.io/feed">
<link rel="shortcut icon" href="/img/favicon.png">

<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
<link rel="stylesheet" href="//static.druid.io/web-assets/bootstrap/3.3.5/css/bootstrap.min.css">

<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700,300italic|Open+Sans:300italic,400italic,600italic,400,300,600,700' rel='stylesheet' type='text/css'>

<link rel="stylesheet" href="/css/main.css">
<link rel="stylesheet" href="/css/header.css">
<link rel="stylesheet" href="/css/footer.css">
<link rel="stylesheet" href="/css/syntax.css">
<link rel="stylesheet" href="/css/docs.css">

<script>
  (function() {
    var cx = '000162378814775985090:molvbm0vggm';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>


  </head>
  <body>	
    <!-- Start page_header include -->
<div class="navbar navbar-inverse navbar-static-top druid-nav">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/"><span class="druid-logo"></span></a>
    </div>
    <div class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
        <li class=""><a href="/druid.html">Overview</a></li>
        <li class=""><a href="/downloads.html">Download</a></li>
        <li class=""><a href="/docs/0.12.1/design/index.html">Docs</a></li>
        <li class=""><a href="/community/">Contribute</a></li>
        <li class=""><a href="/blog">Blog</a></li>
        <li><a href="https://twitter.com/druidio/" class="fa fa-twitter"></a></li>
        <li><a href="https://github.com/druid-io/druid/" class="fa fa-github"></a></li>
      </ul>
    </div>
  </div>
</div>
<!-- Stop page_header include -->


    <link rel="stylesheet" href="/css/blogs.css">

<div class="blog druid-header">
  <div class="row">
    <div class="col-md-8 col-md-offset-2">
      <div class="title-image-wrap">
        
      </div>
    </div>
  </div>
</div>

<div class="container blog">
  <div class="row">
    <div class="col-md-8 col-md-offset-2">
      <div class="blog-entry">
        <h1>Understanding Druid Real-time Ingestion</h1>
        <p class="text-muted">by <span class="author text-uppercase">Russell Jurney</span> Â· August 30, 2013</p>

        <p>In our last post, we got a realtime node working with example Twitter data. Now it&#39;s time to load our own data to see how Druid performs. Druid can ingest data in three ways: via Kafka and a realtime node, via the indexing service, and via the Hadoop batch loader. Data is ingested in realtime using a <a href="https://github.com/metamx/druid/wiki/Firehose">Firehose</a>. In this post we&#39;ll outline how to ingest data from Kafka in realtime using the Kafka Firehose.</p>

<h2 id="about-druid">About Druid</h2>

<p>Druid is a rockin&#39; exploratory analytical data store capable of offering interactive query of big data in realtime - as data is ingested. Druid drives 10&#39;s of billions of events per day for the <a href="http://www.metamarkets.com">Metamarkets</a> platform, and Metamarkets is committed to building Druid in open source.</p>

<p>To learn more check out the first blog in this series <a href="http://druid.io/blog/2013/08/06/twitter-tutorial.html">Understanding Druid Via Twitter Data</a></p>

<p>Checkout Druid at XLDB on Sept 9th <a href="https://conf-slac.stanford.edu/xldb-2013/tutorials#amC">XLDB</a></p>

<p>Druid is available <a href="https://github.com/metamx/druid">here</a>.</p>

<h2 id="create-config-directories">Create Config Directories</h2>

<p>Each type of node needs its own config file and directory, so create these subdirectories under the druid directory.</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>mkdir config
mkdir config/realtime
</code></pre></div>
<h2 id="loading-data-with-kafka">Loading Data with Kafka</h2>

<p><a href="https://github.com/metamx/druid/blob/master/realtime/src/main/java/com/metamx/druid/realtime/firehose/KafkaFirehoseFactory.java">KafkaFirehoseFactory</a> is how druid communicates with Kafka. Using this Firehose with the right configuration, we can import data into Druid in realtime without writing any code. To load data to a realtime node via Kafka, we&#39;ll first need to initialize Zookeeper and Kafka, and then configure and initialize a Realtime node.</p>

<h3 id="booting-kafka">Booting Kafka</h3>

<p>Instructions for booting a Zookeeper and then Kafka cluster are available <a href="http://kafka.apache.org/07/quickstart.html">here</a>.</p>

<p><strong>Download Apache Kafka</strong> 0.7.2 from <a href="http://static.druid.io/artifacts/kafka-0.7.2-incubating-bin.tar.gz">http://static.druid.io/artifacts/kafka-0.7.2-incubating-bin.tar.gz</a></p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>wget http://static.druid.io/artifacts/kafka-0.7.2-incubating-bin.tar.gz
tar -xvzf kafka-0.7.2-incubating-bin.tar.gz
cd kafka-0.7.2-incubating-bin
</code></pre></div>
<p><strong>Boot Zookeeper and Kafka</strong></p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>cat config/zookeeper.properties
bin/zookeeper-server-start.sh config/zookeeper.properties
# in a new console
bin/kafka-server-start.sh config/server.properties
</code></pre></div>
<p><strong>Launch Kafka</strong></p>

<p>In a new console, launch the kafka console producer (so you can type in JSON kafka messages in a bit)</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>bin/kafka-console-producer.sh --zookeeper localhost:2181 --topic druidtest
</code></pre></div>
<h3 id="launching-a-realtime-node">Launching a Realtime Node</h3>

<p><strong>Download Druid</strong></p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>wget http://static.druid.io/artifacts/releases/druid-services-0.5.50-bin.tar.gz
tar -xvzf druid-services-0.5.50-bin.tar.gz
cd druid-services-0.5.50-bin
</code></pre></div>
<p><strong>Create a valid configuration file</strong> similar to this called config/realtime/runtime.properties:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>druid.host=127.0.0.1
druid.port=8083

com.metamx.emitter.logging=true

druid.processing.formatString=processing_%s
druid.processing.numThreads=1
druid.processing.buffer.sizeBytes=10000000

druid.service=example

druid.request.logging.dir=/tmp/example/log
druid.realtime.specFile=realtime.spec
com.metamx.emitter.logging=true
com.metamx.emitter.logging.level=info

com.metamx.aws.accessKey=dummy_access_key
com.metamx.aws.secretKey=dummy_secret_key
druid.pusher.s3.bucket=dummy_s3_bucket

druid.zk.service.host=localhost
druid.server.maxSize=300000000000
druid.zk.paths.base=/druid
druid.database.segmentTable=prod_segments
druid.database.user=user
druid.database.password=diurd
druid.database.connectURI=
druid.host=127.0.0.1:8083
</code></pre></div>
<p><strong>Create a valid realtime configuration file</strong> similar to this called realtime.spec in the current directory:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>[{
  &quot;schema&quot; : { &quot;dataSource&quot;:&quot;druidtest&quot;,
               &quot;aggregators&quot;:[ {&quot;type&quot;:&quot;count&quot;, &quot;name&quot;:&quot;impressions&quot;},
                                  {&quot;type&quot;:&quot;doubleSum&quot;,&quot;name&quot;:&quot;wp&quot;,&quot;fieldName&quot;:&quot;wp&quot;}],
               &quot;indexGranularity&quot;:&quot;minute&quot;,
           &quot;shardSpec&quot; : { &quot;type&quot;: &quot;none&quot; } },
  &quot;config&quot; : { &quot;maxRowsInMemory&quot; : 500000,
               &quot;intermediatePersistPeriod&quot; : &quot;PT10m&quot; },
  &quot;firehose&quot; : { &quot;type&quot; : &quot;kafka-0.7.2&quot;,
                 &quot;consumerProps&quot; : { &quot;zk.connect&quot; : &quot;localhost:2181&quot;,
                                     &quot;zk.connectiontimeout.ms&quot; : &quot;15000&quot;,
                                     &quot;zk.sessiontimeout.ms&quot; : &quot;15000&quot;,
                                     &quot;zk.synctime.ms&quot; : &quot;5000&quot;,
                                     &quot;groupid&quot; : &quot;topic-pixel-local&quot;,
                                     &quot;fetch.size&quot; : &quot;1048586&quot;,
                                     &quot;autooffset.reset&quot; : &quot;largest&quot;,
                                     &quot;autocommit.enable&quot; : &quot;false&quot; },
                 &quot;feed&quot; : &quot;druidtest&quot;,
                 &quot;parser&quot; : { &quot;timestampSpec&quot; : { &quot;column&quot; : &quot;utcdt&quot;, &quot;format&quot; : &quot;iso&quot; },
                              &quot;data&quot; : { &quot;format&quot; : &quot;json&quot; },
                              &quot;dimensionExclusions&quot; : [&quot;wp&quot;] } },
  &quot;plumber&quot; : { &quot;type&quot; : &quot;realtime&quot;,
                &quot;windowPeriod&quot; : &quot;PT10m&quot;,
                &quot;segmentGranularity&quot;:&quot;hour&quot;,
                &quot;basePersistDirectory&quot; : &quot;/tmp/realtime/basePersist&quot;,
                &quot;rejectionPolicy&quot;: {&quot;type&quot;: &quot;messageTime&quot;} }
}]
</code></pre></div>
<p><strong>Launch the realtime node</strong></p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>java -Xmx256m -Duser.timezone=UTC -Dfile.encoding=UTF-8 \
-Ddruid.realtime.specFile=realtime.spec \
-classpath services/target/druid-services-0.5.6-SNAPSHOT-selfcontained.jar:config/realtime \
com.metamx.druid.realtime.RealtimeMain
</code></pre></div>
<p><strong>Paste data into the Kafka console producer</strong></p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>{&quot;utcdt&quot;: &quot;2010-01-01T01:01:01&quot;, &quot;wp&quot;: 1000, &quot;gender&quot;: &quot;male&quot;, &quot;age&quot;: 100}
{&quot;utcdt&quot;: &quot;2010-01-01T01:01:02&quot;, &quot;wp&quot;: 2000, &quot;gender&quot;: &quot;female&quot;, &quot;age&quot;: 50}
{&quot;utcdt&quot;: &quot;2010-01-01T01:01:03&quot;, &quot;wp&quot;: 3000, &quot;gender&quot;: &quot;male&quot;, &quot;age&quot;: 20}
{&quot;utcdt&quot;: &quot;2010-01-01T01:01:04&quot;, &quot;wp&quot;: 4000, &quot;gender&quot;: &quot;female&quot;, &quot;age&quot;: 30}
{&quot;utcdt&quot;: &quot;2010-01-01T01:01:05&quot;, &quot;wp&quot;: 5000, &quot;gender&quot;: &quot;male&quot;, &quot;age&quot;: 40}
</code></pre></div>
<p><strong>Watch the events as they are ingested</strong> in the Druid realtime node console</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>...
2013-06-17 21:41:55,569 INFO [Global--0] com.metamx.emitter.core.LoggingEmitter - Event [{&quot;feed&quot;:&quot;metrics&quot;,&quot;timestamp&quot;:&quot;2013-06-17T21:41:55.569Z&quot;,&quot;service&quot;:&quot;example&quot;,&quot;host&quot;:&quot;127.0.0.1&quot;,&quot;metric&quot;:&quot;events/processed&quot;,&quot;value&quot;:5,&quot;user2&quot;:&quot;druidtest&quot;}]
...
</code></pre></div>
<p><strong>Create a query</strong>
In a new console, edit a file called query.body:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>{
    &quot;queryType&quot;: &quot;groupBy&quot;,
    &quot;dataSource&quot;: &quot;druidtest&quot;,
    &quot;granularity&quot;: &quot;all&quot;,
    &quot;dimensions&quot;: [],
    &quot;aggregations&quot;: [
        { &quot;type&quot;: &quot;count&quot;, &quot;name&quot;: &quot;rows&quot; },
        {&quot;type&quot;: &quot;longSum&quot;, &quot;name&quot;: &quot;imps&quot;, &quot;fieldName&quot;: &quot;impressions&quot;},
        {&quot;type&quot;: &quot;doubleSum&quot;, &quot;name&quot;: &quot;wp&quot;, &quot;fieldName&quot;: &quot;wp&quot;}
    ],
    &quot;intervals&quot;: [&quot;2010-01-01T00:00/2020-01-01T00&quot;]
}
</code></pre></div>
<p><strong>Submit the query via curl</strong></p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>curl -X POST &quot;http://localhost:8083/druid/v2/?pretty&quot; \
-H &#39;content-type: application/json&#39; -d @query.body
</code></pre></div>
<p><strong>View Result!</strong></p>
<div class="highlight"><pre><code class="language-text" data-lang="text"><span></span>[ {
  &quot;timestamp&quot; : &quot;2010-01-01T01:01:00.000Z&quot;,
  &quot;result&quot; : {
    &quot;imps&quot; : 20,
    &quot;wp&quot; : 60000.0,
    &quot;rows&quot; : 5
  }
} ]
</code></pre></div>
<p>Congratulations, you&#39;ve queried the data we just loaded! In our next post, we&#39;ll move on to Querying our Data.</p>

      </div>
      <div id="disqus_thread"></div>
      <script type="text/javascript">
        var disqus_shortname = 'druidio';
        (function() {
         var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
         dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
         (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
         })();
      </script>
      <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
      <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
  </div>
</div>

    
    <!-- Start page_footer include -->
<footer class="druid-footer">
<div class="container">
  <div class="text-center">
    <p>
    <a href="/community/">Community</a>&ensp;Â·&ensp;
    <a href="/downloads.html">Download</a>&ensp;Â·&ensp;
    <a href="/druid-powered.html">Powered by Druid</a>&ensp;Â·&ensp;
    <a href="/faq.html">FAQ</a>&ensp;Â·&ensp;
    <a href="/licensing.html">License</a>
    </p>
  </div>
  <div class="text-center">
    <a href="https://groups.google.com/forum/#!forum/druid-user"><span class="fa fa-lg fa-comments"></span></a>&ensp;Â·&ensp;
    <a href="https://twitter.com/druidio"><span class="fa fa-lg fa-twitter"></span></a>&ensp;Â·&ensp;
    <a href="https://github.com/druid-io/druid"><span class="fa fa-lg fa-github"></span></a>
  </div>
  <div class="text-center license">
    Except where otherwise noted, licensed under <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
  </div>
</div>
</footer>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-40280432-1', 'auto');
  ga('set', 'anonymizeIp', true);
  ga('send', 'pageview');

</script>
<script src="http://code.jquery.com/jquery.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
<script src="/assets/js/druid.js"></script>
<!-- stop page_footer include -->

    
  </body>
</html>
